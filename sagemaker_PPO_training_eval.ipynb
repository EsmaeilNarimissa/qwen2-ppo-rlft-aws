{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Fine-Tuning on AWS SageMaker\n",
    "\n",
    "This notebook launches a SageMaker training job to fine-tune the Qwen2-7B-Instruct model using Proximal Policy Optimization (PPO) for the Countdown math problem task.\n",
    "\n",
    "***Cost Optimization***\n",
    "\n",
    "- Using spot instances (up to 70% cheaper than on-demand)\n",
    "- QLoRA for efficient fine-tuning (reduces memory requirements)\n",
    "- Checkpointing to resume training if interrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q sagemaker boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1.post100\n",
      "Transformers version: 4.49.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import transformers\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SageMaker session\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'countdown-ppo'\n",
    "\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"SageMaker Session Region: {session.boto_region_name}\")\n",
    "print(f\"S3 Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define hyperparameters\n",
    "\n",
    "‚úÖ Key Facts\n",
    "\n",
    "- ***Constraint (PPO trainer requires that:): batch_size must be divisible by mini_batch_size * gradient_accumulation_steps***\n",
    "\n",
    "- **Dataset:** `predibase/countdown`  \n",
    "  - **Training set:** 1,000 samples  \n",
    "  - **Test set:** 500 samples  \n",
    "\n",
    "- **Model:** `Qwen/Qwen2.5-0.5B-Instruct`  \n",
    "  - Small (‚âà0.9 GB), fine-tunable on consumer or cloud GPUs  \n",
    "\n",
    "- **GPU:** `ml.g5.2xlarge` (NVIDIA A10G, 24GB VRAM)  \n",
    "\n",
    "- **Framework:** `trl` PPOTrainer  \n",
    "  - Requires:  \n",
    "    \\[\n",
    "    \\text{batch\\_size} \\mod (\\text{mini\\_batch\\_size} \\times \\text{gradient\\_accumulation\\_steps}) = 0\n",
    "    \\]\n",
    "\n",
    "---\n",
    "\n",
    "üéØ Recommended Hyperparameters (Satisfying PPOTrainer Constraint)\n",
    "\n",
    "Let‚Äôs define:\n",
    "\n",
    "- `mini_batch_size = 4`  \n",
    "- `gradient_accumulation_steps = 2`  \n",
    "Then:\n",
    "- `mini_batch_size * gradient_accumulation_steps = 8`  \n",
    "So, choose a `batch_size` divisible by 8, such as **16**, **32**, etc.\n",
    "\n",
    "‚úÖ Safe, efficient choice:\n",
    "```python\n",
    "hyperparameters = {\n",
    "    'base-model': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
    "    'lora-r': 16,\n",
    "    'lora-alpha': 32,\n",
    "    'lora-dropout': 0.05,\n",
    "    'learning-rate': 1.41e-5,\n",
    "    'max-steps': 200,          # Slightly over 3 epochs (based on 1,000 training samples)\n",
    "    'save-steps': 50,\n",
    "\n",
    "    'batch-size': 16,          # Must be divisible by 4 * 2\n",
    "    'mini-batch-size': 4,      # Each PPO step uses this many samples\n",
    "    'gradient-accumulation-steps': 2\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "üßÆ Training Logic Behind the Numbers\n",
    "\n",
    "- With `batch_size = 16`, and 1,000 training samples:\n",
    "  - Each **epoch** ‚âà 63 steps  \n",
    "  - `max_steps = 200` ‚Üí ~3.17 epochs  \n",
    "\n",
    "- PPO divides `batch_size` into `mini_batch_size` segments:\n",
    "  - Here: 16 / 4 = 4 mini-batches per PPO step  \n",
    "  - Each gradient update accumulates over 2 steps\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Pro Tips\n",
    "\n",
    "- If CUDA OOM occurs:\n",
    "  - Reduce `batch_size` to 8 or 4\n",
    "  - Adjust `mini_batch_size` and `gradient_accumulation_steps` accordingly  \n",
    "    (e.g., 4 = 2 √ó 2 or 2 = 1 √ó 2)\n",
    "\n",
    "- If GPU is underutilized:\n",
    "  - Increase `batch_size` to 32 or 64 (just ensure divisibility)\n",
    "\n",
    "**üß† PPO Training: Valid Batch Configurations (Ensure:** `batch_size % (mini_batch_size √ó gradient_accum_steps) == 0` **)**\n",
    "\n",
    "| `batch_size` | `gradient_accum_steps` | `mini_batch_size` | `batch_size √∑ (g.a. √ó m.b.s)` | Safe?                         |\n",
    "|--------------|------------------------|--------------------|-------------------------------|-------------------------------|\n",
    "| 1            | 1                      | 1                  | 1                             | ‚úÖ Yes ‚Äî very slow            |\n",
    "| 2            | 1                      | 1                  | 2                             | ‚úÖ Yes                        |\n",
    "| 4            | 1                      | 1                  | 4                             | ‚úÖ Good starter config        |\n",
    "| 8            | 1                      | 2                  | 4                             | ‚úÖ Okay ‚Äî monitor VRAM        |\n",
    "| 8            | 2                      | 2                  | 2                             | ‚úÖ Stable + balanced          |\n",
    "| 16           | 2                      | 4                  | 2                             | ‚úÖ Best trade-off             |\n",
    "| 32           | 2                      | 4                  | 4                             | ‚ùå May OOM on 16GB GPUs       |\n",
    "| 32           | 4                      | 4                  | 2                             | ‚úÖ Good on 24GB+ GPUs         |\n",
    "| 64           | 4                      | 8                  | 2                             | ‚ùå Likely OOM on 24GB GPU     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "## Test Training only!\n",
    "# hyperparameters = {\n",
    "#     'base-model': 'Qwen/Qwen2-1.5B-Instruct', # Cahnged from 'Qwen/Qwen2-7B-Instruct'\n",
    "#     'lora-r': 16,\n",
    "#     'lora-alpha': 32,\n",
    "#     'lora-dropout': 0.05,\n",
    "#     'learning-rate': 1.41e-5,\n",
    "#     'max-steps': 1,  # Reduce this for testing or cost savings (original= 100 or 1000)\n",
    "#     'save-steps': 100,\n",
    "#     'batch-size': 1, # Reduce this for testing or cost savings (original= 100 or 1000)\n",
    "#     'gradient-accumulation-steps': 1 # Reduce this for testing or cost savings (original= 4)\n",
    "# }\n",
    "\n",
    "## Real Training (no training plots needed)\n",
    "# hyperparameters = {\n",
    "#     'base-model': 'Qwen/Qwen2-1.5B-Instruct',  # ‚úÖ still a good choice\n",
    "#     'lora-r': 16,\n",
    "#     'lora-alpha': 32,\n",
    "#     'lora-dropout': 0.05,\n",
    "#     'learning-rate': 1.41e-5,\n",
    "#     'max-steps': 200,                   # üîº reasonable for 30‚Äì60 min of training\n",
    "#     'save-steps': 50,                   # üß† save intermediate checkpoints\n",
    "#     'batch-size': 4,                    # üîº GPU can handle this; increase if room\n",
    "#     'gradient-accumulation-steps': 1    # üß† keeps memory use lower, effective batch = 8\n",
    "# }\n",
    "\n",
    "## Real Training (with training plots)\n",
    "hyperparameters = {\n",
    "    'base-model': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
    "    'lora-r': 16,\n",
    "    'lora-alpha': 32,\n",
    "    'lora-dropout': 0.05,\n",
    "    'learning-rate': 1.41e-5,\n",
    "    'max-steps': 200,          # Slightly over 3 epochs (based on 1,000 training samples)\n",
    "    'save-steps': 50,\n",
    "\n",
    "    'batch-size': 16,          # Must be divisible by (mini-batch-sizeXgradient-accumulation-steps)= 4 * 2\n",
    "    'mini-batch-size': 4,      \n",
    "    'gradient-accumulation-steps': 2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create PyTorch estimator\n",
    "\n",
    "We'll use a PyTorch estimator with spot instances for cost savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create PyTorch estimator\n",
    "# Configure SageMaker training job with Spot Instances for cost savings\n",
    "\n",
    "## CPU only\n",
    "# estimator = PyTorch(\n",
    "#     entry_point='train-diag.py',\n",
    "#     source_dir='.',                         # this is where requirements.txt is\n",
    "#     role=role,\n",
    "#     framework_version='2.4.0',\n",
    "#     py_version='py311',\n",
    "#     instance_count=1,\n",
    "#     instance_type='ml.m5.large',   # Revert to 'ml.g5.2xlarge' after debug\n",
    "#     hyperparameters=hyperparameters,\n",
    "#     max_run=1800,\n",
    "#     use_spot_instances=False,      # Revert to True after debug\n",
    "#     #max_wait=72*60*60,\n",
    "#     checkpoint_s3_uri=f's3://{bucket}/{prefix}/checkpoints',\n",
    "#     checkpoint_local_path='/opt/ml/checkpoints',\n",
    "#     dependencies=['.'],  # this tells SageMaker to install requirements.txt before running train.py\n",
    "# )\n",
    "\n",
    "\n",
    "## Small GPU, no spot instance\n",
    "# estimator = PyTorch(\n",
    "#     entry_point='train-diag.py',\n",
    "#     source_dir='.',                          # location of train-diag.py and requirements.txt\n",
    "#     role=role,\n",
    "#     framework_version='2.4.0',\n",
    "#     py_version='py311',\n",
    "#     instance_count=1,\n",
    "#     instance_type='ml.g5.xlarge',            # upgraded from ml.m5.large\n",
    "#     hyperparameters=hyperparameters,\n",
    "#     max_run=1800,                            # 30 minutes for fast debug\n",
    "#     use_spot_instances=False,                # switch to True for cost savings after debug\n",
    "#     checkpoint_s3_uri=f's3://{bucket}/{prefix}/checkpoints',\n",
    "#     checkpoint_local_path='/opt/ml/checkpoints',\n",
    "#     dependencies=['.'],                      # install requirements.txt\n",
    "# )\n",
    "\n",
    "## Large GPU, with spot instance\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir='.',\n",
    "    role=role,\n",
    "    framework_version='2.4.0',\n",
    "    py_version='py311',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',             # or 'ml.g5.12xlarge'\n",
    "    hyperparameters=hyperparameters,\n",
    "    max_run=72*60*60,\n",
    "    use_spot_instances=False,                   # ‚úÖ Enable spot for savings\n",
    "    # max_wait=72*60*60,                         # ‚úÖ Must be included when using spot\n",
    "    checkpoint_s3_uri=f's3://{bucket}/{prefix}/checkpoints',\n",
    "    checkpoint_local_path='/opt/ml/checkpoints',\n",
    "    dependencies=['.'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start training\n",
    "\n",
    "This will launch the training job on SageMaker. The job will run on the specified instance type and use the hyperparameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Real Training (with training plots)\n",
    "hyperparameters = {\n",
    "    'base-model': 'Qwen/Qwen2.5-0.5B-Instruct',\n",
    "    'lora-r': 16,\n",
    "    'lora-alpha': 32,\n",
    "    'lora-dropout': 0.05,\n",
    "    'learning-rate': 1.41e-5,\n",
    "    'max-steps': 200,          # Slightly over 3 epochs (based on 1,000 training samples)\n",
    "    'save-steps': 50,\n",
    "\n",
    "    'batch-size': 16,          # Must be divisible by (mini-batch-sizeXgradient-accumulation-steps)= 4 * 2\n",
    "    'mini-batch-size': 4,      \n",
    "    'gradient-accumulation-steps': 2,\n",
    "}\n",
    "\n",
    "\n",
    "## Large GPU, with spot instance\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir='.',\n",
    "    role=role,\n",
    "    framework_version='2.4.0',\n",
    "    py_version='py311',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',             # or 'ml.g5.12xlarge'\n",
    "    hyperparameters=hyperparameters,\n",
    "    max_run=72*60*60,\n",
    "    use_spot_instances=False,                   # ‚úÖ Enable spot for savings\n",
    "    # max_wait=72*60*60,                         # ‚úÖ Must be included when using spot\n",
    "    checkpoint_s3_uri=f's3://{bucket}/{prefix}/checkpoints',\n",
    "    checkpoint_local_path='/opt/ml/checkpoints',\n",
    "    dependencies=['.'],\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training job...\")\n",
    "estimator.fit(wait=True, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Highlights Summary**\n",
    "\n",
    "1. **Training Start and Configuration**  \n",
    "   The training job began successfully using the `Qwen/Qwen2.5-0.5B-Instruct` model with LoRA applied. Key hyperparameters included:\n",
    "   - `learning_rate`: 1.41e-5  \n",
    "   - `max_steps`: 200  \n",
    "   - `batch_size`: 16  \n",
    "   - `mini_batch_size`: 4  \n",
    "   - `gradient_accumulation_steps`: 2  \n",
    "   - `lora_r`: 16, `lora_alpha`: 32, `lora_dropout`: 0.05  \n",
    "\n",
    "   The system also used a G5 GPU (`ml.g5.2xlarge`) without spot interruptions. Training utilized the `transformers`, `trl`, `peft`, and `datasets` libraries under a stable PyTorch and SageMaker environment.\n",
    "\n",
    "2. **Execution Timeline**  \n",
    "   The training progressed from step 0 to step 62 before early termination. Although `max_steps` was set to 200, the job completed prematurely. The job was marked as **successful** (return code 0) by SageMaker, implying that no internal error caused the interruption‚Äîlikely a timeout or manual stop.\n",
    "\n",
    "3. **Logging and Checkpointing**  \n",
    "   - Logs were saved every 10 steps, and the model was checkpointed at step 60.  \n",
    "   - A TensorBoard writer was initialized and successfully closed at the end.  \n",
    "   - `ppo_training_log.csv` was saved under `/opt/ml/model`, ensuring reward logs were preserved.\n",
    "\n",
    "4. **Reward Signals**  \n",
    "   The **mean reward remained at `0.00` for all 63 logged steps (0‚Äì62)**:\n",
    "   - Format reward and equation reward functions were unable to yield a single positive signal.\n",
    "   - This suggests that the model‚Äôs completions never satisfied the structure or arithmetic correctness defined by your two reward functions.\n",
    "   - Consequently, **no reinforcement signal was given** to guide learning, resulting in ineffective PPO optimization.\n",
    "\n",
    "5. **Successful Completion**  \n",
    "   Despite zero learning signal, the training loop finished gracefully:\n",
    "   - Logs were flushed and saved properly.\n",
    "   - The model and tokenizer were serialized to disk.\n",
    "   - SageMaker reported the training job as ‚Äú**SUCCESS**.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "### **Implications and Recommendations**\n",
    "\n",
    "- The **lack of positive rewards** implies either:\n",
    "  - The reward functions are too strict or misaligned with what the model can produce early in training.\n",
    "  - The model wasn't warm-started properly or initialized with sufficient knowledge to generate structurally valid outputs.\n",
    "  \n",
    "- Consider:\n",
    "  - Lowering the reward function constraints (e.g., accept partial matches, use fuzzy logic).\n",
    "  - Starting with on-demand instances for short debugging runs (10‚Äì20 steps) to verify learning signals.\n",
    "  - Training with supervised learning or reward shaping for a few epochs before applying PPO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Post-Training Visualization: Download and Plot PPO Reward Curves**\n",
    "\n",
    "This cell performs three key actions after your SageMaker training job has finished:\n",
    "\n",
    "1. **Retrieves metadata** from the completed training job, including the job name and the S3 location where model artifacts and logs are stored.\n",
    "2. **Downloads output artifacts** (such as logs) from the `output/data` directory of the training job into a local folder using SageMaker's `download_artifact()` method.\n",
    "3. **Loads and visualizes** the `ppo_training_log.csv` file that was generated during training, which contains step-wise reward values (format reward, equation reward, and total reward). These values are plotted to help analyze how the model‚Äôs reward performance evolved over time.\n",
    "\n",
    "This cell enables a clear post-hoc assessment of your RLHF training dynamics without requiring live monitoring. The resulting plot gives insight into how well your model learned over training steps and whether the reward signals (formatting and equation accuracy) improved.\n",
    "\n",
    "If no CSV file is found, the cell will provide a helpful message indicating where to check for issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Get training job info ---\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "model_artifacts = estimator.model_data\n",
    "print(f\"Job name: {training_job_name}\")\n",
    "print(f\"Model artifacts: {model_artifacts}\")\n",
    "\n",
    "# --- Download model.tar.gz ---\n",
    "bucket = model_artifacts.split(\"/\")[2]\n",
    "key = \"/\".join(model_artifacts.split(\"/\")[3:])\n",
    "local_tar_path = f\"./artifacts/{training_job_name}/model.tar.gz\"\n",
    "os.makedirs(os.path.dirname(local_tar_path), exist_ok=True)\n",
    "\n",
    "boto3.client(\"s3\").download_file(bucket, key, local_tar_path)\n",
    "\n",
    "# --- Extract reward CSV ---\n",
    "extract_path = f\"./artifacts/{training_job_name}/extracted\"\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "with tarfile.open(local_tar_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_path)\n",
    "\n",
    "csv_path = os.path.join(extract_path, \"ppo_training_log.csv\")\n",
    "\n",
    "# --- Plot reward curves ---\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if len(df) > 500:\n",
    "        df = df.groupby(\"step\").mean().reset_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df[\"step\"], df[\"format_reward\"], label=\"Format Reward\")\n",
    "    plt.plot(df[\"step\"], df[\"equation_reward\"], label=\"Equation Reward\")\n",
    "    plt.plot(df[\"step\"], df[\"total_reward\"], label=\"Total Reward\")\n",
    "    plt.xlabel(\"Training Step\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"PPO Rewards over Training\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plot_path = os.path.join(extract_path, \"reward_plot.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    print(f\"üìà Plot saved to: {plot_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"üö´ Log file not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the model\n",
    "\n",
    "After training completes, you can download the model and evaluate it using the evaluate.py script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Run Evaluation on the Extracted Model\n",
    "\n",
    "This step generates a JSON file (evaluation_results.json) containing metrics + completions on test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-10 09:00:25.236167: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "üì• Loading dataset with schema workaround...\n",
      "Direct download failed: 404 Client Error. (Request ID: Root=1-67f788b3-1839b4da418dae3d1f75f572;b68b0506-dd69-4ea3-8ecb-1dea26085f7b)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/datasets/predibase/countdown/resolve/main/test.parquet.\n",
      "Falling back to manual download...\n",
      "üöÄ Loading model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "Created temporary offload directory: /tmp/tmpr4jult_o\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading adapter from: ./artifacts/pytorch-training-2025-04-10-07-57-35-919/extracted\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Model loaded successfully\n",
      "üîç Evaluating...\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "\n",
      "‚úÖ Evaluation complete. Results saved to evaluation_results.json\n",
      "üìä Format Score:   0.0000\n",
      "üßÆ Equation Score: 0.0000\n",
      "üîó Combined Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# !pip install peft datasets pyarrow --quiet\n",
    "\n",
    "!python evaluate.py \\\n",
    "    --model-dir ./artifacts/{training_job_name}/extracted \\\n",
    "    --base-model {hyperparameters['base-model']} \\\n",
    "    --output-file evaluation_results.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Analyze & Visualize Evaluation Results\n",
    "This script performs **post-evaluation analysis** on the model's performance:\n",
    "\n",
    "1. **Loads** the `evaluation_results.json` file produced by `evaluate.py`.\n",
    "2. **Prints** overall evaluation metrics (e.g., average format and equation scores).\n",
    "3. **Displays**:\n",
    "   - The **worst-performing** example (lowest combined reward).\n",
    "   - The **best-performing** example (highest combined reward).\n",
    "4. **Plots histograms** to visualize the distribution of:\n",
    "   - Format scores\n",
    "   - Equation scores\n",
    "\n",
    "In short, it gives you both **quantitative metrics** and **qualitative insight** into how well your trained model is reasoning and calculating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation Metrics:\n",
      "avg_format_score: 0.0000\n",
      "avg_equation_score: 0.0000\n",
      "combined_score: 0.0000\n",
      "num_examples: 5\n",
      "\n",
      "‚ùå Example with lowest score:\n",
      "{\n",
      "  \"prompt\": \"<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process step by step and then provide the user with an answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [1, 2, 3, 4], create an equation that equals 24. You can use basic arithmetic operations (+, -, *, /) and parentheses, and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\",\n",
      "  \"completion\": \" First, I'll try to maximize the left side of the equation using addition. Since we have four numbers, I'll start by adding the largest two together: 4 + 3 = 7. This leaves us with 24 - 7 = 17. Now I need to balance the equation by subtracting some smaller numbers from the right side. Let's start with 16, which is close to our target of 17 but not quite there yet. So, I'll add 1 to get 17. Now my equation looks like this:\\n<answer>\\n(1 + 2) * (4 - 1)\\n</answer>\",\n",
      "  \"format_score\": 0.0,\n",
      "  \"equation_score\": 0.0\n",
      "}\n",
      "\n",
      "‚úÖ Example with highest score:\n",
      "{\n",
      "  \"prompt\": \"<|im_start|>system\\nYou are a helpful assistant. You first think about the reasoning process step by step and then provide the user with an answer.<|im_end|>\\n<|im_start|>user\\nUsing the numbers [1, 5, 8, 9], create an equation that equals 40. You can use basic arithmetic operations (+, -, *, /) and parentheses, and each number can only be used once. Show your work in <think> </think> tags. And return the final equation and answer in <answer> </answer> tags, for example <answer> (1 + 2) / 3 </answer>.<|im_end|>\\n<|im_start|>assistant\\nLet me solve this step by step.\\n<think>\",\n",
      "  \"completion\": \" First, we need to identify which combination of numbers and operations will give us a result of 40. We can try different combinations:\\n(1+2)*3 = 6*3 = 18\\n(9-5)/2 = 4/2 = 2\\n(8+1)*2 = 9*2 = 18\\n(8+1)/2 = 9/2 = 4.5\\n</think>\\nNow let's see if any of these combinations add up to 40:\\n(1+5)*8 = 6*8 = 48\\nThis doesn't work because it gives us 48 instead of 40.\\n(1+5)*8\",\n",
      "  \"format_score\": 0.0,\n",
      "  \"equation_score\": 0.0\n",
      "}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load evaluation results\n",
    "with open(\"evaluation_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Display overall metrics\n",
    "metrics = data[\"metrics\"]\n",
    "print(\"üìä Evaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "\n",
    "# Show examples with low and high reward\n",
    "examples = data[\"examples\"]\n",
    "sorted_examples = sorted(examples, key=lambda x: x[\"equation_score\"] + x[\"format_score\"])\n",
    "\n",
    "print(\"\\n‚ùå Example with lowest score:\")\n",
    "print(json.dumps(sorted_examples[0], indent=2))\n",
    "\n",
    "print(\"\\n‚úÖ Example with highest score:\")\n",
    "print(json.dumps(sorted_examples[-1], indent=2))\n",
    "\n",
    "# Histogram of reward distribution\n",
    "format_scores = [ex[\"format_score\"] for ex in examples]\n",
    "equation_scores = [ex[\"equation_score\"] for ex in examples]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(format_scores, bins=5, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Format Score Distribution\")\n",
    "plt.xlabel(\"Score\"); plt.ylabel(\"Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(equation_scores, bins=5, color='salmon', edgecolor='black')\n",
    "plt.title(\"Equation Score Distribution\")\n",
    "plt.xlabel(\"Score\"); plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) Deploy the model\n",
    "\n",
    "After training completes, you can deploy the model to a SageMaker endpoint for inference. This is optional and can be done later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to deploy the model\n",
    "# predictor = estimator.deploy(\n",
    "#    initial_instance_count=1,\n",
    "#    instance_type='ml.g5.xlarge',\n",
    "#    endpoint_name='countdown-grpo-endpoint'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
